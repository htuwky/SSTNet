import os
import torch
import torch.optim as optim # Keep this for compatibility, though not used in main
import numpy as np
from tqdm import tqdm
import sys
import argparse # [æ–°å¢] å¯¼å…¥ argparse

# å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from models.sstnet import SSTNet
from utils.dataloader import get_loader


def main():
    # --- 1. å‚æ•°è§£æ ---
    parser = argparse.ArgumentParser(description="Extract SSTNet features for MIL training.")
    parser.add_argument('--fold', type=int, required=True, choices=[0, 1, 2, 3],
                        help='Which cross-validation fold model to load for feature extraction.')
    args = parser.parse_args()

    FOLD_IDX = args.fold # [ä¿®æ”¹] åŠ¨æ€è®¾ç½® Fold Index

    # 1. é…ç½®
    MODEL_PATH = os.path.join(config.PROJECT_ROOT, 'checkpoints', f'best_model_fold{FOLD_IDX}.pth')
    OUTPUT_FILE = os.path.join(config.OUTPUT_DIR, f'mil_features_fold{FOLD_IDX}.npy')

    device = torch.device(config.DEVICE)

    print(f"\nğŸš€ Starting feature extraction using Fold {FOLD_IDX} model...")
    print(f"ğŸ’¾ Features will be saved to: {OUTPUT_FILE}")

    # 2. åŠ è½½æ¨¡å‹
    print(f"ğŸ”„ Loading model from {MODEL_PATH}...")
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ Model file not found! Please run train.py --fold {FOLD_IDX} first.")
        return

    model = SSTNet().to(device)
    checkpoint = torch.load(MODEL_PATH, map_location=device) # [ä¼˜åŒ–] å¢åŠ  map_location
    if 'model' in checkpoint:
        model.load_state_dict(checkpoint['model'])
    else:
        model.load_state_dict(checkpoint)

    model.eval()

    # 3. å‡†å¤‡æ•°æ®
    print("ğŸ”„ Preparing DataLoaders (Train + Val)...")
    # æˆ‘ä»¬éœ€è¦æ‰€æœ‰äººçš„æ•°æ®ï¼Œæ‰€ä»¥åŠ è½½ Fold 0 çš„ train å’Œ val å°±æ¶µç›–äº†å…¨é›†
    # [ä¿®æ”¹] ä½¿ç”¨ config.BATCH_SIZE
    loader_train = get_loader('train', fold_idx=0, batch_size=config.BATCH_SIZE)
    loader_val = get_loader('val', fold_idx=0, batch_size=config.BATCH_SIZE)

    # 4. ç‰¹å¾æå–ä¸»å¾ªç¯
    patient_data = {}

    print("Start extraction...")

    with torch.no_grad():
        for loader in [loader_train, loader_val]:
            # [ä¿®æ”¹] è§£åŒ… 6 ä¸ªå˜é‡ (é€‚é… v2.0)
            for local_vis, global_vis, physio, mask, label, subject_ids in tqdm(loader):
                local_vis = local_vis.to(device)
                global_vis = global_vis.to(device).squeeze(1)  # [B, 1, 512] -> [B, 512]
                physio = physio.to(device)
                mask = mask.to(device)

                # [ä¿®æ”¹] ä¼ å…¥ 4 ä¸ªå‚æ•°ï¼Œå¹¶å¼€å¯ return_feats=True
                feats = model(local_vis, global_vis, physio, mask, return_feats=True)

                # è½¬ä¸º CPU numpy
                feats_np = feats.cpu().numpy()
                labels_np = label.numpy()

                # å½’æ¡£
                for i, subj_id in enumerate(subject_ids):
                    if subj_id not in patient_data:
                        patient_data[subj_id] = {
                            'features': [],
                            'label': labels_np[i]
                        }
                    patient_data[subj_id]['features'].append(feats_np[i])

    # 5. æ•´ç†ä¸ä¿å­˜
    print("ğŸ“¦ Packaging data...")
    final_data = {}
    counts = []

    for subj, data in patient_data.items():
        # [ä¼˜åŒ–] å°†ç‰¹å¾åˆ—è¡¨è½¬ä¸º numpy æ•°ç»„
        feats_matrix = np.array(data['features'], dtype=np.float32)
        label = data['label']

        final_data[subj] = {
            'features': feats_matrix,
            'label': label
        }
        counts.append(len(feats_matrix))

    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    np.save(OUTPUT_FILE, final_data)

    print(f"âœ… Features saved to: {OUTPUT_FILE}")
    print(f"ğŸ“Š Stats: Total Patients: {len(final_data)}")
    print(f"   Images per Patient: Min={min(counts)}, Max={max(counts)}, Mean={np.mean(counts):.1f}")


if __name__ == "__main__":
    main()