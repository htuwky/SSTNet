import os
import torch
import numpy as np
from tqdm import tqdm
import sys
import os
# å°†å½“å‰è„šæœ¬çš„çˆ¶ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆå³é¡¹ç›®æ ¹ç›®å½•ï¼‰åŠ å…¥ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from models.sstnet import SSTNet
from utils.dataloader import get_loader


def main():
    # 1. é…ç½®
    # å‡è®¾æˆ‘ä»¬è¦ç”¨ Fold 2 çš„æ¨¡å‹æ¥æå–ç‰¹å¾ (å› ä¸ºä¹‹å‰ Fold 2 æ•ˆæœæœ€å¥½)
    FOLD_IDX = 3
    MODEL_PATH = os.path.join(config.PROJECT_ROOT, 'checkpoints', f'best_model_fold{FOLD_IDX}.pth')
    OUTPUT_FILE = os.path.join(config.OUTPUT_DIR, f'mil_features_fold{FOLD_IDX}.npy')

    device = torch.device(config.DEVICE)

    # 2. åŠ è½½æ¨¡å‹
    print(f"ğŸš€ Loading model from {MODEL_PATH}...")
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ Model file not found! Please run train.py --fold {FOLD_IDX} first.")
        return

    model = SSTNet().to(device)
    checkpoint = torch.load(MODEL_PATH)
    # å…¼å®¹ä¿å­˜çš„æ˜¯ state_dict è¿˜æ˜¯æ•´ä¸ª checkpoint
    if 'model' in checkpoint:
        model.load_state_dict(checkpoint['model'])
    else:
        model.load_state_dict(checkpoint)

    model.eval()

    # 3. å‡†å¤‡æ•°æ®
    # æˆ‘ä»¬éœ€è¦æå–æ‰€æœ‰äººçš„æ•°æ®ã€‚
    # æœ€ç®€å•çš„æ–¹æ³•æ˜¯åˆ†åˆ«åŠ è½½ train å’Œ valï¼Œç„¶ååˆå¹¶ã€‚
    # ä¸ºäº†ç¡®ä¿è¦†ç›– 100% çš„æ•°æ®ï¼Œæˆ‘ä»¬è¿™é‡ŒåŠ è½½ Fold 0 çš„ train å’Œ val (å®ƒä»¬åŠ èµ·æ¥å°±æ˜¯å…¨é›†)
    print("ğŸ”„ Preparing DataLoaders...")
    loader_train = get_loader('train', fold_idx=0, batch_size=64)
    loader_val = get_loader('val', fold_idx=0, batch_size=64)

    # 4. ç‰¹å¾æå–ä¸»å¾ªç¯
    # å­—å…¸ç»“æ„: { '101': {'features': [], 'label': 0}, '102': ... }
    patient_data = {}

    print("Start extraction...")

    with torch.no_grad():
        # éå†ä¸¤ä¸ª Loader (è¦†ç›–æ‰€æœ‰ 160 äºº)
        for loader in [loader_train, loader_val]:
            for visual, physio, mask, label, subject_ids in tqdm(loader):
                visual = visual.to(device)
                physio = physio.to(device)
                mask = mask.to(device)

                # [å…³é”®] å¼€å¯ return_feats=True
                # feats: [Batch, 1024]
                feats = model(visual, physio, mask, return_feats=True)

                # è½¬ä¸º CPU numpy
                feats_np = feats.cpu().numpy()
                labels_np = label.numpy()

                # [æ ¸å¿ƒé€»è¾‘] æŒ‰ ID å½’æ¡£
                for i, subj_id in enumerate(subject_ids):
                    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ä¸ªç—…äººï¼Œåˆå§‹åŒ–å­—å…¸
                    if subj_id not in patient_data:
                        patient_data[subj_id] = {
                            'features': [],
                            'label': labels_np[i]  # è®°å½•æ ‡ç­¾
                        }

                    # å°†è¯¥å›¾ç‰‡çš„ç‰¹å¾åŠ å…¥åˆ—è¡¨
                    patient_data[subj_id]['features'].append(feats_np[i])

    # 5. æ•´ç†ä¸ä¿å­˜
    print("ğŸ“¦ Packaging data...")
    final_data = {}

    # ç»Ÿè®¡ä¸€ä¸‹æ¯ä¸ªäººçš„å›¾ç‰‡æ•°é‡
    counts = []

    for subj, data in patient_data.items():
        # list -> numpy array [N, 1024]
        feats_matrix = np.array(data['features'])
        label = data['label']

        final_data[subj] = {
            'features': feats_matrix,
            'label': label
        }
        counts.append(len(feats_matrix))

    # ä¿å­˜
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    np.save(OUTPUT_FILE, final_data)

    print(f"âœ… Features saved to: {OUTPUT_FILE}")
    print(f"ğŸ“Š Stats: Total Patients: {len(final_data)}")
    print(f"   Images per Patient: Min={min(counts)}, Max={max(counts)}, Mean={np.mean(counts):.1f}")
    if min(counts) < 100:
        print("â„¹ï¸ Note: Variable sequence lengths detected and handled automatically.")


if __name__ == "__main__":
    main()