import torch
import torch.nn as nn
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

from models.temporal_stream import TemporalStream
from models.spatial_stream import NetVLAD


class SSTNet(nn.Module):
    def __init__(self):
        super(SSTNet, self).__init__()

        # 1. é™ç»´å±‚ (512 -> 128)
        self.input_proj = nn.Sequential(
            nn.Linear(config.INPUT_DIM, config.HIDDEN_DIM),
            nn.ReLU(),
            nn.LayerNorm(config.HIDDEN_DIM),
            nn.Dropout(0.1)
        )

        # 2. å·¦è‡‚ï¼šæ—¶åºæµ (æ¥æ”¶ Global)
        self.temporal_stream = TemporalStream(
            input_dim=config.HIDDEN_DIM,  # 128
            clip_dim=config.INPUT_DIM,  # [æ–°å¢] 512 (ç”¨äºGlobal Proj)
            physio_dim=config.PHYSIO_DIM,
            max_len=config.MAX_SEQ_LEN,
            num_layers=config.TEMP_LAYERS,
            nhead=config.TEMP_HEADS,
            dim_feedforward=config.TEMP_FF_DIM,
            dropout=config.TEMP_DROPOUT
        )

        # 3. å³è‡‚ï¼šç©ºé—´æµ (åªçœ‹ Local)
        self.spatial_stream = NetVLAD(
            dim=config.HIDDEN_DIM,  # 128
            num_clusters=config.SPATIAL_CLUSTERS,
            out_dim=config.SPATIAL_OUT_DIM,  # 128
            alpha=config.SPATIAL_ALPHA
        )

        # 4. åˆ†ç±»å¤´
        fusion_dim = config.HIDDEN_DIM + config.SPATIAL_OUT_DIM
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, config.CLS_HIDDEN_DIM),
            nn.BatchNorm1d(config.CLS_HIDDEN_DIM),
            nn.ReLU(),
            nn.Dropout(config.CLS_DROPOUT),
            nn.Linear(config.CLS_HIDDEN_DIM, 1)
        )

    def forward(self, local_visual, global_visual, physio, mask, return_feats=False):
        # 1. å±€éƒ¨ç‰¹å¾é™ç»´: [B, 32, 512] -> [B, 32, 128]
        local_low = self.input_proj(local_visual)

        # 2. æ—¶åºæµ (ä¼ å…¥ Global)
        temp_feat = self.temporal_stream(local_low, global_visual, physio, mask)

        # 3. ç©ºé—´æµ (åªä¼  Local)
        spatial_feat = self.spatial_stream(local_low, mask=mask)

        # 4. èåˆ
        fusion_feat = torch.cat([temp_feat, spatial_feat], dim=1)

        if return_feats:
            return fusion_feat

        logits = self.classifier(fusion_feat)
        return logits


# --- ç®€å•çš„æµ‹è¯•ä»£ç  (é€‚é… v2.0 å…¨å±€æ„ŸçŸ¥ç‰ˆ) ---
if __name__ == "__main__":
    print("ğŸš€ Testing SSTNet Assembly (v2.0)...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = SSTNet().to(device)

    # æ¨¡æ‹Ÿå‚æ•°
    B = 2
    L = config.MAX_SEQ_LEN  # 32
    D = config.INPUT_DIM  # 512 (CLIP åŸå§‹ç»´åº¦)

    # 1. æ„é€ å±€éƒ¨ç‰¹å¾ (Local Patches) -> [Batch, 32, 512]
    dummy_local = torch.randn(B, L, D).to(device)

    # 2. [æ–°å¢] æ„é€ å…¨å±€ç‰¹å¾ (Global Context) -> [Batch, 512]
    # æ³¨æ„ï¼šDataLoader ç»™å‡ºçš„é€šå¸¸æ˜¯ [Batch, 512] æˆ– [Batch, 1, 512]
    # æˆ‘ä»¬çš„ forward ä¼šå¤„ç†å®ƒ
    dummy_global = torch.randn(B, D).to(device)

    # 3. æ„é€ ç”Ÿç†ç‰¹å¾ -> [Batch, 32, 4]
    dummy_phy = torch.randn(B, L, 4).to(device)

    # 4. æ„é€  Mask -> [Batch, 32]
    dummy_mask = torch.ones(B, L).to(device)
    dummy_mask[1, 20:] = 0  # æ¨¡æ‹Ÿç¬¬äºŒä¸ªæ ·æœ¬åé¢æ˜¯ Padding

    # æ‰§è¡Œå‰å‘ä¼ æ’­
    # å‚æ•°é¡ºåº: local, global, physio, mask
    output = model(dummy_local, dummy_global, dummy_phy, dummy_mask)

    print(f"Input Local:  {dummy_local.shape}")
    print(f"Input Global: {dummy_global.shape}")
    print(f"Input Physio: {dummy_phy.shape}")
    print(f"Output Shape: {output.shape} (Expect [2, 1])")

    if output.shape == (2, 1):
        print("âœ… Assembly Success!")
    else:
        print("âŒ Shape mismatch!")