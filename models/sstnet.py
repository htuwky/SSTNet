import torch
import torch.nn as nn
import sys
import os

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

from models.temporal_stream import TemporalStream
from models.spatial_stream import NetVLAD
# [æ–°å¢] å¯¼å…¥ç»“æ„æµ (GNN)
from models.structural_stream import StructuralStream


class SSTNet(nn.Module):
    """
    SSTNet v3.0: Tri-stream Architecture (Spatio-Temporal-Structural)
    èåˆäº†ä¸‰ç§è§†è§’çš„ç‰¹å¾ï¼š
    1. Temporal Stream (Transformer): æ•æ‰æ—¶åºé€»è¾‘ä¸å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ã€‚
    2. Spatial Stream (NetVLAD): æ•æ‰å…¨å±€å†…å®¹ç»Ÿè®¡åˆ†å¸ƒã€‚
    3. Structural Stream (GNN): æ•æ‰å±€éƒ¨æ³¨è§†ç‚¹çš„å‡ ä½•æ‹“æ‰‘ç»“æ„ã€‚
    """

    def __init__(self):
        super(SSTNet, self).__init__()

        # 1. å±€éƒ¨ç‰¹å¾é™ç»´å±‚ (CLIP 512 -> 128)
        self.input_proj = nn.Sequential(
            nn.Linear(config.INPUT_DIM, config.HIDDEN_DIM),
            nn.ReLU(),
            nn.LayerNorm(config.HIDDEN_DIM),
            nn.Dropout(0.1)
        )

        # 2. å·¦è·¯ï¼šæ—¶åºæµ (Transformer) - The "Time"
        self.temporal_stream = TemporalStream(
            input_dim=config.HIDDEN_DIM,
            clip_dim=config.INPUT_DIM,
            physio_dim=config.PHYSIO_DIM,  # 2 (x, y)
            max_len=config.MAX_SEQ_LEN,
            num_layers=config.TEMP_LAYERS,
            nhead=config.TEMP_HEADS,
            dim_feedforward=config.TEMP_FF_DIM,
            dropout=config.TEMP_DROPOUT
        )

        # 3. å³è·¯ï¼šç©ºé—´æµ (NetVLAD) - The "Content"
        self.spatial_stream = NetVLAD(
            dim=config.HIDDEN_DIM,
            num_clusters=config.SPATIAL_CLUSTERS,
            out_dim=config.SPATIAL_OUT_DIM,
            alpha=config.SPATIAL_ALPHA
        )

        # [æ–°å¢] 4. ä¸­è·¯ï¼šç»“æ„æµ (GNN) - The "Structure"
        # ä½¿ç”¨ PyG å®ç°çš„åŠ¨æ€å›¾å·ç§¯
        self.structural_stream = StructuralStream()

        # 5. åˆ†ç±»å¤´ (Classifier)
        # èåˆç»´åº¦ = 128 (Time) + 128 (Space) + 128 (Structure) = 384
        fusion_dim = config.HIDDEN_DIM * 3
        self.stream_attention = StreamAttention(total_dim=config.HIDDEN_DIM * 3, num_streams=3)
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, config.CLS_HIDDEN_DIM),
            nn.BatchNorm1d(config.CLS_HIDDEN_DIM),
            nn.ReLU(),
            nn.Dropout(config.CLS_DROPOUT),
            nn.Linear(config.CLS_HIDDEN_DIM, 1)
        )
        # [æ–°å¢] 6. å¯¹æ¯”å­¦ä¹ æŠ•å½±å¤´ (Projection Head)
        # å°† 384 ç»´ç‰¹å¾æ˜ å°„åˆ° 128 ç»´ç”¨äºè®¡ç®—å¯¹æ¯” Loss
        self.projector = nn.Sequential(
            nn.Linear(config.HIDDEN_DIM * 3, config.HIDDEN_DIM * 3),
            nn.ReLU(),
            nn.Linear(config.HIDDEN_DIM * 3, 128)  # å‹ç¼©åˆ° 128 ç»´
        )

    def forward(self, local_visual, global_visual, physio, mask, return_feats=False, return_proj=False):
        """
        Args:
            local_visual:  [Batch, Seq, 512]
            global_visual: [Batch, 512]
            physio:        [Batch, Seq, 2] (x, y)
            mask:          [Batch, Seq]
        """
        # 1. å±€éƒ¨ç‰¹å¾é™ç»´ [B, N, 512] -> [B, N, 128]
        local_low = self.input_proj(local_visual)

        # 2. æ—¶åºæµ (Temporal)
        temp_feat = self.temporal_stream(local_low, global_visual, physio, mask)

        # 3. ç©ºé—´æµ (Spatial)
        spatial_feat = self.spatial_stream(local_low, mask=mask)

        # [æ–°å¢] 4. ç»“æ„æµ (Structural)
        # æ³¨æ„ï¼šæ˜¾å¼ä¼ å…¥ physio (x,y) ç”¨äºåŠ¨æ€å»ºå›¾ (KNN)
        # struct_feat = self.structural_stream(local_low, physio)
        struct_feat = self.structural_stream(local_low, physio, mask)
        # 5. ä¸‰æµèåˆ
        # fusion_feat = torch.cat([temp_feat, spatial_feat, struct_feat], dim=1)
        stream_list = [temp_feat, spatial_feat, struct_feat]
        fusion_feat, weights = self.stream_attention(stream_list)
        # [ä¿®æ”¹] å„ç§è¿”å›æ¨¡å¼
        if return_feats:
            return fusion_feat  # ä¾› MIL æå–ç‰¹å¾ç”¨

        logits = self.classifier(fusion_feat)

        # [æ–°å¢] å¦‚æœè®­ç»ƒæ—¶å¼€å¯å¯¹æ¯”å­¦ä¹ ï¼Œè¿”å› (logits, projections)
        if return_proj:
            # æŠ•å½±å¹¶å½’ä¸€åŒ– (SupCon å¿…é¡»å½’ä¸€åŒ–)
            proj = self.projector(fusion_feat)
            proj = torch.nn.functional.normalize(proj, dim=1)
            return logits, proj

        return logits


class StreamAttention(nn.Module):
    """
    [æ–°å¢ç»„ä»¶] æµæ³¨æ„åŠ›æ¨¡å—
    æ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€è®¡ç®—ä¸‰ä¸ªæµçš„æƒé‡ (w1, w2, w3)
    """

    def __init__(self, total_dim=384, num_streams=3):
        super().__init__()
        # ä¸€ä¸ªéå¸¸å°çš„ MLP: 384 -> 64 -> 3
        self.attn_net = nn.Sequential(
            nn.Linear(total_dim, total_dim // 4),  # é™ç»´å‡å°‘å‚æ•°
            nn.ReLU(),
            nn.Linear(total_dim // 4, num_streams),
            nn.Softmax(dim=1)  # ä¿è¯æƒé‡ä¹‹å’Œä¸º 1
        )

    def forward(self, x_list):
        """
        Args:
            x_list: [feat1, feat2, feat3] åˆ—è¡¨
        """
        # 1. å…ˆæ‹¼æ¥æ‹¿åˆ°å…¨é‡ç‰¹å¾
        cat_feat = torch.cat(x_list, dim=1)

        # 2. è®¡ç®—æƒé‡ [Batch, 3]
        weights = self.attn_net(cat_feat)

        # 3. åŠ æƒ (æ³¨æ„: ä¿æŒç»´åº¦ç‹¬ç«‹ï¼Œä¸æ˜¯ç›¸åŠ ï¼Œè€Œæ˜¯åŠ æƒæ‹¼æ¥)
        # æˆ‘ä»¬å¸Œæœ›ä¿ç•™ 384 ç»´ï¼Œåªæ˜¯è®©æŸäº›æµå˜å¼º/å˜å¼±
        weighted_list = []
        for i, feat in enumerate(x_list):
            # weights[:, i] å½¢çŠ¶æ˜¯ [B], éœ€è¦ unsqueeze æˆ [B, 1]
            w = weights[:, i].unsqueeze(1)
            weighted_list.append(feat * w)

        # 4. å†æ¬¡æ‹¼æ¥ä½œä¸ºè¾“å‡º
        return torch.cat(weighted_list, dim=1), weights
# ==========================================
# ç®€å•çš„è‡ªæ£€ä»£ç  (è¿è¡Œ python models/sstnet.py)
# ==========================================
if __name__ == "__main__":
    print("ğŸš€ Testing SSTNet v3.0 (Tri-stream)...")
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # å°è¯•åˆå§‹åŒ–æ¨¡å‹
    try:
        model = SSTNet().to(device)
        print("âœ… Model initialized successfully.")
    except Exception as e:
        print(f"âŒ Model initialization failed: {e}")
        exit()

    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    B = 2
    L = config.MAX_SEQ_LEN
    D_in = config.INPUT_DIM

    dummy_local = torch.randn(B, L, D_in).to(device)  # [2, 32, 512]
    dummy_global = torch.randn(B, D_in).to(device)  # [2, 512]
    dummy_physio = torch.rand(B, L, config.PHYSIO_DIM).to(device)  # [2, 32, 2] (X,Y 0~1)
    dummy_mask = torch.ones(B, L).to(device)  # [2, 32]

    # æ‰§è¡Œå‰å‘ä¼ æ’­
    try:
        output = model(dummy_local, dummy_global, dummy_physio, dummy_mask)
        print(f"âœ… Forward pass successful!")
        print(f"   Input Shapes: Local={dummy_local.shape}, Global={dummy_global.shape}, Physio={dummy_physio.shape}")
        print(f"   Output Shape: {output.shape} (Expected: [2, 1])")

        # æ£€æŸ¥èåˆç»´åº¦æ˜¯å¦æ­£ç¡® (ç®€å•åæ¨)
        # fusion_dim åº”è¯¥æ˜¯ 128*3=384ã€‚å¯ä»¥åœ¨è¿™é‡Œæ‰“å°æ¨¡å‹å‚æ•°é‡ç¡®è®¤ã€‚
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   Total Parameters: {total_params:,}")

    except Exception as e:
        print(f"âŒ Forward pass failed: {e}")
        import traceback

        traceback.print_exc()