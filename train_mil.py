import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score
from tqdm import tqdm
import argparse
import sys

# å¯¼å…¥é…ç½®å’Œæ¨¡å‹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))  # ç¡®ä¿èƒ½æ‰¾åˆ°æ ¹ç›®å½•
import config
from models.mil_model import RobustGatedAttention
from utils.misc import fix_seed


# 1. æ•°æ®é›†ç±» (ä¿æŒä¸å˜)
# train_mil.py ä¸­çš„ MILDataset ç±»

class MILDataset(Dataset):
    def __init__(self, features_file, fold_idx=0, set_name='train', seed=42):
        print(f"ğŸ”„ [{set_name.upper()}] Loading features from: {features_file}")
        try:
            self.data = np.load(features_file, allow_pickle=True).item()
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ File not found: {features_file}")

        # --- [æ ¸å¿ƒä¿®æ­£] è¯»å– Excel è¿›è¡Œå®˜æ–¹åˆ’åˆ† (ä¸ train.py ä¿æŒä¸€è‡´) ---
        import pandas as pd
        excel_path = os.path.join(config.DATASET_DIR, 'Train_Valid.xlsx')
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"âŒ Excel file not found: {excel_path}")

        df = pd.read_excel(excel_path)
        folds = ['Set_0', 'Set_1', 'Set_2', 'Set_3']

        # ç¡®å®šå½“å‰æŠ˜çš„ç›®æ ‡ ID
        val_col = folds[fold_idx]
        train_cols = [f for f in folds if f != val_col]

        target_ids = []
        if set_name == 'val':
            # éªŒè¯é›†
            raw_ids = df[val_col].dropna().values
            target_ids = [str(int(i)).zfill(3) for i in raw_ids]
        else:
            # è®­ç»ƒé›†
            for col in train_cols:
                raw_ids = df[col].dropna().values
                target_ids.extend([str(int(i)).zfill(3) for i in raw_ids])

        # è¿‡æ»¤ï¼šåªä¿ç•™åœ¨ feature_file (.npy) é‡Œå­˜åœ¨çš„ ID
        # (å› ä¸ºæœ‰äº› ID å¯èƒ½æ²¡çœ‹å›¾æˆ–è€…æ•°æ®æŸåè¢«è¿‡æ»¤äº†)
        self.subjects = [sid for sid in target_ids if sid in self.data]

        # æ‰“å°ç»Ÿè®¡
        labels = [self.data[s]['label'] for s in self.subjects]
        if len(labels) > 0:
            pos = sum(labels)
            print(
                f"âœ… {set_name.upper()}: {len(self.subjects)} patients (Pos: {int(pos)}, Neg: {len(labels) - int(pos)})")
        else:
            print(f"âš ï¸ {set_name.upper()}: 0 patients found! Check fold index.")

    def __len__(self):
        return len(self.subjects)

    def __getitem__(self, idx):
        subj_id = self.subjects[idx]
        item = self.data[subj_id]
        features = torch.FloatTensor(item['features'])
        label = torch.tensor(item['label'], dtype=torch.float)
        return features, label


# 2. è®­ç»ƒå‡½æ•° (ä¿æŒä¸å˜)
def train_epoch(model, loader, optimizer, criterion, device):
    model.train()
    epoch_loss = 0
    for features, label in loader:
        features, label = features.to(device), label.to(device)
        optimizer.zero_grad()
        logits, _ = model(features)
        loss = criterion(logits.squeeze(1), label)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    return epoch_loss / len(loader)


# 3. éªŒè¯å‡½æ•° (ä¿æŒä¸å˜)
def validate(model, loader, device):
    model.eval()
    all_probs = []
    all_labels = []
    with torch.no_grad():
        for features, label in loader:
            features = features.to(device)
            logits, _ = model(features)
            probs = torch.sigmoid(logits).cpu().numpy().flatten()
            all_probs.extend(probs)
            all_labels.extend(label.numpy())
    try:
        auc = roc_auc_score(all_labels, all_probs)
        acc = accuracy_score(all_labels, np.array(all_probs) > 0.5)
    except ValueError:
        auc = 0.5
        acc = 0.5
    return auc, acc


# 4. ä¸»å‡½æ•° (æ ¸å¿ƒä¿®æ”¹)
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--fold', type=int, default=2, help='Which fold features to use')
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--dropout', type=float, default=0.5)
    parser.add_argument('--seed', type=int, default=42)
    args = parser.parse_args()

    fix_seed(args.seed)
    device = torch.device(config.DEVICE if torch.cuda.is_available() else "cpu")

    # è·¯å¾„æ„å»º
    feature_file = os.path.join(config.OUTPUT_DIR, f'mil_features_fold{args.fold}.npy')
    if not os.path.exists(feature_file):
        print(f"âŒ Error: Feature file not found at {feature_file}")
        return

    # åŠ è½½æ•°æ®
    train_set = MILDataset(feature_file, fold_idx=args.fold, set_name='train')
    val_set = MILDataset(feature_file, fold_idx=args.fold, set_name='val')

    # [å…³é”®ä¿®æ”¹] è‡ªåŠ¨æ¢æµ‹ç»´åº¦
    sample_feat, _ = train_set[0]
    detected_dim = sample_feat.shape[1]
    print(f"ğŸš€ Start MIL Training (Robust Gated Attention)")
    print(f"   Feature Source: Fold {args.fold}")
    print(f"   Detected Dimension: {detected_dim}")  # åº”è¯¥ä¼šæ‰“å° 2560
    print(f"   Params: LR={args.lr}, Dropout={args.dropout}")

    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)

    # æ„å»ºæ¨¡å‹ (ä½¿ç”¨æ£€æµ‹åˆ°çš„ç»´åº¦)
    # model = RobustGatedAttention(input_dim=detected_dim, hidden_dim=256, dropout=args.dropout).to(device)
    model = RobustGatedAttention(input_dim=detected_dim, bottleneck_dim=32, hidden_dim=128, dropout=args.dropout).to(
        device)
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-3)
    criterion = nn.BCEWithLogitsLoss()

    best_auc = 0.0

    for epoch in range(args.epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        auc, acc = validate(model, val_loader, device)

        print(f"Epoch {epoch + 1:02d}: Loss={train_loss:.4f}, Val AUC={auc:.4f}, Acc={acc:.4f}")

        if auc > best_auc:
            best_auc = auc
            # [ä¼˜åŒ–] ä¿å­˜åˆ° checkpoints æ–‡ä»¶å¤¹ï¼Œå¹¶å¸¦ä¸Š fold åç¼€
            save_dir = os.path.join(config.PROJECT_ROOT, 'checkpoints')
            os.makedirs(save_dir, exist_ok=True)

            save_path = os.path.join(save_dir, f"best_mil_model_fold{args.fold}.pth")
            torch.save(model.state_dict(), save_path)
            print(f"  --> ğŸ’¾ New Best Saved: {save_path}")

    print("=" * 40)
    print(f"ğŸ† Final Best Patient-Level AUC: {best_auc:.4f}")
    print("=" * 40)


if __name__ == "__main__":
    main()