# utils/dataloader.py

import os
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config


class SSTDataset(Dataset):
    def __init__(self, set_name, fold_idx=0):
        self.set_name = set_name
        self.max_len = config.MAX_SEQ_LEN

        # åŠ è½½ç‰¹å¾
        print(f"ğŸ”„ [{set_name.upper()}] Loading visual features from {config.CLIP_TRAIN_FEATURE_FILE} ...")
        try:
            self.visual_data = np.load(config.CLIP_TRAIN_FEATURE_FILE, allow_pickle=True).item()
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ Feature file not found! Run generate_clip_features.py --train first.")

        self.samples = self._split_dataset(fold_idx)
        print(f"âœ… {set_name.upper()} set loaded: {len(self.samples)} samples.")

    def _split_dataset(self, fold_idx):
        # ... (ä¿æŒåŸæœ‰çš„åˆ’åˆ†é€»è¾‘ä¸å˜) ...
        excel_path = os.path.join(config.DATASET_DIR, 'Train_Valid.xlsx')
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"âŒ Excel file not found: {excel_path}")

        df = pd.read_excel(excel_path)
        folds = ['Set_0', 'Set_1', 'Set_2', 'Set_3']
        val_col = folds[fold_idx]
        train_cols = [f for f in folds if f != val_col]

        target_ids = []
        if self.set_name == 'val':
            raw_ids = df[val_col].dropna().values
            target_ids = [str(int(i)).zfill(3) for i in raw_ids]
        else:
            for col in train_cols:
                raw_ids = df[col].dropna().values
                target_ids.extend([str(int(i)).zfill(3) for i in raw_ids])

        sample_list = []
        txt_folder = config.TRAIN_TXT_DIR
        all_files = os.listdir(txt_folder)

        for f in all_files:
            if not f.endswith('.txt'): continue
            filename_no_ext = f.split('.txt')[0]
            try:
                subj_id, _ = filename_no_ext.split('_', 1)
            except ValueError:
                continue

            if subj_id in target_ids:
                label = 0 if int(subj_id) < 200 else 1
                if filename_no_ext in self.visual_data:
                    sample_list.append({
                        'key': filename_no_ext,
                        'txt_path': os.path.join(txt_folder, f),
                        'label': label
                    })
        return sample_list

    def __getitem__(self, idx):
        item = self.samples[idx]
        key = item['key']
        txt_path = item['txt_path']
        label = item['label']

        # --- A. è·å–åŒæµè§†è§‰ç‰¹å¾ ---
        data_pack = self.visual_data[key]
        visual_local = data_pack['local']  # [Seq, 512]
        visual_global = data_pack['global']  # [1, 512]

        # --- B. è·å–ç”Ÿç†ç‰¹å¾ (æ ¸å¿ƒä¿®æ”¹éƒ¨åˆ†) ---
        # è¿™é‡Œçš„é•¿åº¦ä»¥è§†è§‰ç‰¹å¾ä¸ºå‡†
        curr_len = visual_local.shape[0]

        # å…ˆåˆå§‹åŒ–ä¸º 2ç»´ (x,y)
        physio_base = np.zeros((curr_len, 2), dtype=np.float32)

        try:
            df = pd.read_csv(txt_path, header=None)
            raw_data = df.iloc[:, 1:3].values.astype(np.float32)  # åªè¯» X, Y

            # å½’ä¸€åŒ–
            min_vec = np.array([config.SCREEN_X_MIN, config.SCREEN_Y_MIN], dtype=np.float32)
            max_vec = np.array([config.SCREEN_X_MAX, config.SCREEN_Y_MAX], dtype=np.float32)

            raw_data = np.clip(raw_data, min_vec, max_vec)
            norm_0_1 = (raw_data - min_vec) / (max_vec - min_vec + 1e-6)

            # è¿™é‡Œçš„é•¿åº¦å¯èƒ½ä¸ä¸€è‡´ï¼ˆè™½ç„¶é€šå¸¸ä¸€è‡´ï¼‰ï¼Œåšä¸ªå®‰å…¨æˆªæ–­
            valid_p_len = min(len(norm_0_1), curr_len)
            physio_base[:valid_p_len] = norm_0_1[:valid_p_len] * 2 - 1

        except Exception:
            pass

        # [æ–°å¢] 1. è®¡ç®—é€Ÿåº¦å·®åˆ†ç‰¹å¾ (Delta X, Delta Y)
        # -----------------------------------------------------------
        diff = np.zeros_like(physio_base)
        # åä¸€é¡¹å‡å‰ä¸€é¡¹ï¼Œç¬¬ä¸€å¸§é€Ÿåº¦è®¾ä¸º0
        diff[1:] = physio_base[1:] - physio_base[:-1]

        # [æ–°å¢] 2. æ‹¼æ¥æˆ 4ç»´ç‰¹å¾ (X, Y, dX, dY)
        physio_feat_4d = np.concatenate([physio_base, diff], axis=-1)
        # -----------------------------------------------------------

        # --- æ•°æ®å¢å¼º (ä»…è®­ç»ƒé›†) ---
        if self.set_name == 'train':
            # 1. ç‰¹å¾åŠ å™ª
            noise_level = 0.015
            noise = np.random.normal(0, noise_level, visual_local.shape).astype(np.float32)
            visual_local = visual_local + noise

            # 2. æ—¶åºéšæœºä¸¢å¼ƒ
            drop_prob = 0.15
            seq_len_origin = visual_local.shape[0]
            drop_mask = (np.random.rand(seq_len_origin) > drop_prob).astype(np.float32)
            drop_mask = drop_mask[:, np.newaxis]

            visual_local = visual_local * drop_mask
            # [ä¿®æ”¹] è¿™é‡Œçš„å¢å¼ºè¦åº”ç”¨åˆ°æ–°çš„ 4D ç‰¹å¾ä¸Š
            physio_feat_4d = physio_feat_4d * drop_mask

        # --- C. ç»Ÿä¸€é•¿åº¦ (Padding) ---
        target_len = self.max_len
        valid_len = min(curr_len, target_len)

        padded_local = np.zeros((target_len, config.INPUT_DIM), dtype=np.float32)
        # [ä¿®æ”¹] ç»´åº¦æ˜¯ 4
        padded_physio = np.zeros((target_len, 4), dtype=np.float32)
        mask = np.zeros(target_len, dtype=np.float32)

        # å¡«å……æœ‰æ•ˆæ•°æ®
        padded_local[:valid_len] = visual_local[:valid_len]
        padded_physio[:valid_len] = physio_feat_4d[:valid_len]
        mask[:valid_len] = 1.0

        # [æ–°å¢] 3. è¾¹ç¼˜å¡«å…… (Edge Padding)
        # -----------------------------------------------------------
        # å¦‚æœåºåˆ—ä¸å¤Ÿé•¿ï¼Œå‰©ä¸‹çš„ä½ç½®å¡«â€œæœ€åä¸€å¸§çš„å€¼â€ï¼Œè€Œä¸æ˜¯ 0
        # è¿™æ · GNN ä¼šè®¤ä¸ºçœ¼ç›åœ¨æœ€ååœç•™äº†ï¼Œè€Œä¸æ˜¯ç¬ç§»åˆ°äº†åŸç‚¹ (0,0)
        if valid_len < target_len and valid_len > 0:
            last_val = physio_feat_4d[valid_len - 1]  # è·å–æœ€åä¸€å¸§ (4ç»´)
            padded_physio[valid_len:] = last_val  # å¹¿æ’­å¡«å……åˆ°å‰©ä½™ä½ç½®
        # -----------------------------------------------------------

        subject_id_str = key.split('_', 1)[0]

        return (
            torch.FloatTensor(padded_local),
            torch.FloatTensor(visual_global),
            torch.FloatTensor(padded_physio),
            torch.FloatTensor(mask),
            torch.tensor(label, dtype=torch.long),
            subject_id_str
        )

    def __len__(self):
        return len(self.samples)


def get_loader(set_name, fold_idx=0, batch_size=config.BATCH_SIZE):
    dataset = SSTDataset(set_name, fold_idx)
    shuffle = True if set_name == 'train' else False
    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)