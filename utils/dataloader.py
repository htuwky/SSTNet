import os
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import sys

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½ import config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config


class SSTDataset(Dataset):
    def __init__(self, set_name, fold_idx=0):
        """
        Args:
            set_name: 'train' æˆ– 'val'
            fold_idx: å½“å‰æ˜¯ç¬¬å‡ æŠ˜äº¤å‰éªŒè¯ (0-3)
        """
        self.set_name = set_name
        self.max_len = config.MAX_SEQ_LEN

        # 1. åŠ è½½è§†è§‰ç‰¹å¾å¤§å­—å…¸ (.npy)
        # æ ¼å¼: {'Subject_Image': [Seq_Len, 512]}
        print(f"ğŸ”„ [{set_name.upper()}] Loading visual features from {config.CLIP_FEATURE_FILE} ...")
        try:
            self.visual_data = np.load(config.CLIP_FEATURE_FILE, allow_pickle=True).item()
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ Feature file not found! Please run generate_clip_features.py first.")

        # 2. è·å–æ•°æ®åˆ—è¡¨ (æ ¹æ® Train_Valid.xlsx å’Œ fold_idx åˆ’åˆ†)
        self.samples = self._split_dataset(fold_idx)
        print(f"âœ… {set_name.upper()} set loaded: {len(self.samples)} samples.")

    def _split_dataset(self, fold_idx):
        """
        è¯»å– Train_Valid.xlsxï¼Œæ ¹æ® fold_idx å°†å—è¯•è€…åˆ’åˆ†ä¸ºè®­ç»ƒé›†æˆ–éªŒè¯é›†ã€‚
        å¹¶æ‰¾åˆ°è¿™äº›å—è¯•è€…å¯¹åº”çš„æ‰€æœ‰ TXT æ•°æ®æ–‡ä»¶ã€‚
        """
        excel_path = os.path.join(config.DATASET_DIR, 'Train_Valid.xlsx')
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"âŒ Excel file not found: {excel_path}")

        df = pd.read_excel(excel_path)
        folds = ['Set_0', 'Set_1', 'Set_2', 'Set_3']

        # ç¡®å®šå½“å‰æŠ˜çš„ç›®æ ‡å—è¯•è€… ID åˆ—è¡¨
        val_col = folds[fold_idx]
        train_cols = [f for f in folds if f != val_col]

        target_ids = []
        if self.set_name == 'val':
            # éªŒè¯é›†: åªå– val_col åˆ—çš„ ID
            raw_ids = df[val_col].dropna().values
            target_ids = [str(int(i)).zfill(3) for i in raw_ids]
        else:
            # è®­ç»ƒé›†: åˆå¹¶å…¶ä»– 3 åˆ—çš„ ID
            for col in train_cols:
                raw_ids = df[col].dropna().values
                target_ids.extend([str(int(i)).zfill(3) for i in raw_ids])

        # éå† TXT æ–‡ä»¶å¤¹ï¼ŒåŒ¹é…å±äº target_ids çš„æ–‡ä»¶
        sample_list = []
        txt_folder = config.TXT_DIR
        if not os.path.exists(txt_folder):
            raise FileNotFoundError(f"âŒ TXT folder not found: {txt_folder}")

        all_files = os.listdir(txt_folder)

        for f in all_files:
            if not f.endswith('.txt'): continue

            # æ–‡ä»¶åè§£æ: SubjectID_ImageName.txt
            filename_no_ext = f.split('.txt')[0]
            try:
                # å‡è®¾è§„åˆ™: ID_ImageName (åªåˆ‡ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿)
                subj_id, _ = filename_no_ext.split('_', 1)
            except ValueError:
                continue

            # åŒ¹é… ID
            if subj_id in target_ids:
                # æ ‡ç­¾è§„åˆ™: ID < 200 ä¸º HC(0), >= 200 ä¸º SZ(1)
                label = 0 if int(subj_id) < 200 else 1

                # [å…³é”®] å¿…é¡»åŒæ—¶åœ¨ .npy é‡Œæœ‰è§†è§‰ç‰¹å¾æ‰ç®—æœ‰æ•ˆæ•°æ®
                if filename_no_ext in self.visual_data:
                    sample_list.append({
                        'key': filename_no_ext,
                        'txt_path': os.path.join(txt_folder, f),
                        'label': label
                    })

        return sample_list

    def __getitem__(self, idx):
        item = self.samples[idx]
        key = item['key']
        txt_path = item['txt_path']
        label = item['label']
        subject_id_str = key.split('_', 1)[0]
        # --- A. è·å–è§†è§‰ç‰¹å¾ (Visual) ---
        # Shape: [Seq_Len, 512]
        visual_feat = self.visual_data[key]

        # --- B. è·å–ç”Ÿç†ç‰¹å¾ (Physio) å¹¶æ˜ å°„ ---
        try:
            # è¯»å– TXT: Index, X, Y, Duration, Pupil
            df = pd.read_csv(txt_path, header=None)

            # å–ç¬¬ 1,2,3,4 åˆ— (X, Y, Duration, Pupil)
            # Shape: [Seq_Len, 4]
            raw_data = df.iloc[:, 1:5].values.astype(np.float32)

            # 1. å‡†å¤‡è¾¹ç•Œå€¼ (ä» config è¯»å–ï¼Œé¡ºåºå¿…é¡»å¯¹åº”)
            min_vec = np.array([config.SCREEN_X_MIN, config.SCREEN_Y_MIN, config.DUR_MIN, config.PUPIL_MIN],
                               dtype=np.float32)
            max_vec = np.array([config.SCREEN_X_MAX, config.SCREEN_Y_MAX, config.DUR_MAX, config.PUPIL_MAX],
                               dtype=np.float32)

            # 2. æˆªæ–­ç¦»ç¾¤å€¼ (Clip) - ä¿æŠ¤å½’ä¸€åŒ–ä¸è¢«æå€¼ç ´å
            raw_data = np.clip(raw_data, min_vec, max_vec)

            # 3. Min-Max å½’ä¸€åŒ–åˆ° 0~1
            # åŠ  1e-6 é˜²æ­¢é™¤ä»¥ 0
            norm_0_1 = (raw_data - min_vec) / (max_vec - min_vec + 1e-6)

            # 4. æ˜ å°„åˆ° -1~1 (ä¸ CLIP ç‰¹å¾å¯¹é½)
            physio_feat = norm_0_1 * 2 - 1

        except Exception:
            # å®¹é”™å¤„ç†ï¼šå¦‚æœè¯»å–å¤±è´¥ï¼Œç»™å…¨0 (ç†è®ºä¸Šå‰é¢è¿‡æ»¤è¿‡ç©ºæ–‡ä»¶ï¼Œä¸ä¼šè§¦å‘)
            physio_feat = np.zeros((visual_feat.shape[0], config.PHYSIO_DIM), dtype=np.float32)

        # --- C. ç»Ÿä¸€é•¿åº¦ & ç”Ÿæˆ Mask ---
        seq_len = visual_feat.shape[0]
        target_len = self.max_len

        # åˆå§‹åŒ–å®¹å™¨ (å…¨ 0 ä»£è¡¨ Padding)
        padded_visual = np.zeros((target_len, config.INPUT_DIM), dtype=np.float32)
        padded_physio = np.zeros((target_len, config.PHYSIO_DIM), dtype=np.float32)
        mask = np.zeros(target_len, dtype=np.float32)  # 0=Pad, 1=Real

        # æˆªå–æœ‰æ•ˆé•¿åº¦ (é˜²æ­¢æ•°æ®è¶…è¿‡ 32)
        valid_len = min(seq_len, target_len)

        # å¡«å…¥çœŸå®æ•°æ®
        padded_visual[:valid_len] = visual_feat[:valid_len]
        # å¦‚æœ txt è¡Œæ•°å°‘äº npy (ç½•è§)ï¼Œè¿™é‡Œä¼šè‡ªåŠ¨åˆ‡ç‰‡åŒ¹é…ï¼›å¦‚æœå¤šäºï¼Œä¹Ÿä¼šæˆªæ–­
        # ä¸ºäº†å®‰å…¨ï¼Œå–ä¸¤è€…æœ€å°è¡Œæ•°ä½œä¸ºå¡«å……é•¿åº¦
        fill_len = min(valid_len, physio_feat.shape[0])
        padded_physio[:fill_len] = physio_feat[:fill_len]

        # æ ‡è®° Mask (æœ‰æ•°æ®çš„åœ°æ–¹è®¾ä¸º 1)
        mask[:fill_len] = 1.0

        # è¿”å› Tensor
        return (
            torch.FloatTensor(padded_visual),  # [32, 512]
            torch.FloatTensor(padded_physio),  # [32, 4]
            torch.FloatTensor(mask),  # [32]
            torch.tensor(label, dtype=torch.long),  # Scalar (0/1)
            subject_id_str  # 5. [æ–°å¢] å—è¯•è€…ID (å­—ç¬¦ä¸²)
        )

    def __len__(self):
        return len(self.samples)


def get_loader(set_name, fold_idx=0, batch_size=config.BATCH_SIZE):
    """
    è·å– DataLoader çš„ä¾¿æ·å‡½æ•°
    """
    dataset = SSTDataset(set_name, fold_idx)

    # è®­ç»ƒé›†æ‰“ä¹±ï¼ŒéªŒè¯é›†ä¸æ‰“ä¹±
    shuffle = True if set_name == 'train' else False

    loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=0,  # Windowsä¸‹å»ºè®®è®¾ä¸º0é¿å…å¤šè¿›ç¨‹æŠ¥é”™ï¼ŒLinuxå¯è®¾ä¸º4
        pin_memory=True
    )
    return loader


# --- ç®€å•çš„æµ‹è¯•å— (ç›´æ¥è¿è¡Œæ­¤è„šæœ¬å¯æµ‹è¯•) ---
if __name__ == "__main__":
    print("ğŸš€ Testing DataLoader...")
    try:
        # å°è¯•åŠ è½½ç¬¬ 0 æŠ˜çš„è®­ç»ƒé›†ï¼Œå– 2 ä¸ªæ ·æœ¬
        loader = get_loader('train', fold_idx=0, batch_size=2)

        for vis, phy, mask, label in loader:
            print(f"  Visual Shape: {vis.shape} (Expect [2, {config.MAX_SEQ_LEN}, 512])")
            print(f"  Physio Shape: {phy.shape} (Expect [2, {config.MAX_SEQ_LEN}, 4])")
            print(f"  Mask Shape:   {mask.shape} (Expect [2, {config.MAX_SEQ_LEN}])")
            print(f"  Label:        {label} (Expect [0/1, 0/1])")

            # æ£€æŸ¥å½’ä¸€åŒ–èŒƒå›´
            print(f"  Physio Min/Max: {phy.min():.2f} / {phy.max():.2f} (Expect approx -1 to 1)")

            # æ£€æŸ¥ Mask æ˜¯å¦ç”Ÿæ•ˆ (æ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æœ‰æ•ˆé•¿åº¦)
            valid_len = mask[0].sum().item()
            print(f"  Sample 0 Valid Length: {int(valid_len)}")
            break

        print("âœ… DataLoader test passed!")
    except Exception as e:
        print(f"âŒ DataLoader test failed: {e}")
        import traceback

        traceback.print_exc()