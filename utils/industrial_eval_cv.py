import os
import torch
import numpy as np
from tqdm import tqdm
from sklearn.metrics import confusion_matrix
import argparse
import sys

# å¼•å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from models.sstnet import SSTNet
from utils.dataloader import get_loader


def calculate_industrial_metrics(y_true, y_probs, threshold=0.5):
    """ è®¡ç®—å·¥ä¸šçº§æ ¸å¿ƒæŒ‡æ ‡ """
    y_pred = (y_probs > threshold).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()

    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0
    npv = tn / (tn + fn) if (tn + fn) > 0 else 0

    return {
        "Threshold": threshold,
        "Sens": sensitivity,
        "Spec": specificity,
        "PPV": ppv,
        "NPV": npv
    }


def scan_thresholds(y_true, y_probs):
    """ ç­–ç•¥A: é˜ˆå€¼æ‰«æ """
    print("\nğŸ“Š === Strategy A: Threshold Scanning (Full Dataset OOF) ===")
    print(f"{'Thres':<6} | {'Sens (æ¼è¯Šç‡)':<12} | {'Spec (è¯¯è¯Šç‡)':<12} | {'PPV':<8} | {'NPV':<8}")
    print("-" * 65)

    best_score = 0
    best_threshold = 0.5

    # æ‰«æ 0.3 åˆ° 0.9
    for th in np.arange(0.3, 0.95, 0.05):
        m = calculate_industrial_metrics(y_true, y_probs, threshold=th)
        print(f"{th:.2f}   | {m['Sens']:.4f}       | {m['Spec']:.4f}       | {m['PPV']:.4f}   | {m['NPV']:.4f}")

        # å¯»æ‰¾ç”œç‚¹ï¼šå‡è®¾ Sens æƒé‡ä¸º 2ï¼ŒSpec æƒé‡ä¸º 1
        # ç¡¬æ€§è¦æ±‚ï¼šSensitivity å¿…é¡» > 0.85 (ä¸èƒ½æ¼å¤ªå¤š)
        score = 2 * m['Sens'] + m['Spec']
        if score > best_score and m['Sens'] > 0.85:
            best_score = score
            best_threshold = th

    print("-" * 65)
    print(f"ğŸ’¡ Recommended Threshold: {best_threshold:.2f}")
    return best_threshold


def evaluate_grey_zone(y_true, y_probs, low_th=0.3, high_th=0.7):
    """ ç­–ç•¥B: ç°åŒºåˆ†æ """
    print(f"\nğŸš¦ === Strategy B: Grey Zone Analysis [{low_th} - {high_th}] ===")

    y_true = np.array(y_true)
    y_probs = np.array(y_probs)

    certain_mask = (y_probs < low_th) | (y_probs > high_th)
    uncertain_mask = ~certain_mask

    n_total = len(y_true)
    n_uncertain = np.sum(uncertain_mask)

    print(f"Total Samples: {n_total}")
    print(f"Gray Zone (Need Doctor): {n_uncertain} ({n_uncertain / n_total * 100:.1f}%)")
    print(f"Auto-Processed:        {n_total - n_uncertain}")

    if np.sum(certain_mask) > 0:
        y_pred_certain = (y_probs[certain_mask] > high_th).astype(int)
        y_true_certain = y_true[certain_mask]
        acc_certain = np.mean(y_pred_certain == y_true_certain)
        print(f"âœ… Accuracy in Auto Zone: {acc_certain * 100:.2f}%")

        # æ£€æŸ¥æ”¾è¡ŒåŒºæ˜¯å¦æœ‰æ¼ç½‘ä¹‹é±¼
        missed = np.sum((y_true == 1) & (y_probs < low_th))
        print(f"âš ï¸ Critical Misses (Green Zone): {missed}")


def main():
    device = torch.device(config.DEVICE)

    # å®¹å™¨ï¼šå­˜æ”¾æ‰€æœ‰æŠ˜çš„é¢„æµ‹ç»“æœ
    oof_labels = []
    oof_probs = []

    print("ğŸš€ Starting 4-Fold Cross-Validation Evaluation (OOF)...")

    # éå† 4 ä¸ªæŠ˜
    for fold_idx in range(4):
        print(f"\nğŸ”„ Processing Fold {fold_idx}...")

        # 1. æ„é€ æ¨¡å‹è·¯å¾„
        ckpt_path = os.path.join(config.PROJECT_ROOT, 'checkpoints', f'best_model_fold{fold_idx}.pth')
        if not os.path.exists(ckpt_path):
            print(f"âš ï¸ Warning: Checkpoint for Fold {fold_idx} not found! Skipping.")
            continue

        # 2. åŠ è½½æ¨¡å‹
        model = SSTNet().to(device)
        checkpoint = torch.load(ckpt_path, map_location=device)
        if 'model' in checkpoint:
            model.load_state_dict(checkpoint['model'])
        else:
            model.load_state_dict(checkpoint)
        model.eval()

        # 3. åŠ è½½è¯¥æŠ˜å¯¹åº”çš„éªŒè¯é›† (Val Set)
        # æ³¨æ„ï¼šget_loader('val', fold_idx) ä¼šè‡ªåŠ¨è¿”å›è¿™ä¸€æŠ˜æ²¡å‚ä¸è®­ç»ƒçš„æ•°æ®
        val_loader = get_loader('val', fold_idx=fold_idx, batch_size=config.BATCH_SIZE)

        # 4. æ¨ç†
        fold_probs = []
        fold_labels = []

        with torch.no_grad():
            for local_vis, global_vis, physio, mask, label, _ in tqdm(val_loader, desc=f"Fold {fold_idx}"):
                local_vis = local_vis.to(device)
                global_vis = global_vis.to(device).squeeze(1)
                physio = physio.to(device)
                mask = mask.to(device)

                logits = model(local_vis, global_vis, physio, mask)
                probs = torch.sigmoid(logits).cpu().numpy().flatten()

                fold_probs.extend(probs)
                fold_labels.extend(label.numpy())

        # æ”¶é›†ç»“æœ
        oof_labels.extend(fold_labels)
        oof_probs.extend(fold_probs)

    # 5. å…¨å±€è¯„ä¼°
    if len(oof_labels) == 0:
        print("âŒ No data collected. Please check if checkpoints exist.")
        return

    print("\n" + "=" * 50)
    print(f"ğŸŒ GLOBAL EVALUATION (Total Samples: {len(oof_labels)})")
    print("=" * 50)

    # å°†åˆ—è¡¨è½¬ numpy
    oof_labels = np.array(oof_labels)
    oof_probs = np.array(oof_probs)

    # è¿è¡Œç­–ç•¥åˆ†æ
    best_th = scan_thresholds(oof_labels, oof_probs)
    evaluate_grey_zone(oof_labels, oof_probs, low_th=0.3, high_th=0.7)


if __name__ == "__main__":
    main()